setup:
  seed: 42
  experiment_name: classification
  is_train: True
  ckpt_path: null
  pretrained_ckpt_path: null

cudnn:
  benchmark: True
  deterministic: False
  enabled: True

dataloader:
  seed: 42
  batch_size: 96
  pin_memory: true
  num_workers: 4
  train_ds:
    name: imagenet
    split: train
  val_ds:
    name: imagenet
    split: val

transform:
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  out_size: [224, 224]

model:
  architecture: HRNet

module:
  optimizers:
    optim:
      name: SGD
      params:
        lr: 0.133 # 0.1 * ((2*96)/(4*36)) scale LR from paper by my batch_size (96) and GPU (2)
        momentum: 0.9
        weight_decay: 0.0001
        nesterov: True
  lr_schedulers:
    optim:
      name: MultiStepLR
      interval: epoch
      params:
        milestones: [30, 60, 90]
        gamma: 0.1

trainer:
  accelerator: gpu
  max_epochs: 100
  limit_batches: -1
  log_every_n_steps: 0
  use_DDP: true
  use_DP: false
  sync_batchnorm: false
