setup:
  seed: 42
  experiment_name: classification
  architecture: ClassificationHRNet
  dataset: ImageNet
  run_name: null
  is_train: True
  ckpt_path: null
  pretrained_ckpt_path: null
  deterministic: False

trainer:
  accelerator: gpu
  max_epochs: 100
  limit_batches: -1
  use_DDP: true
  sync_batchnorm: false
  use_compile: false

cudnn:
  benchmark: True
  deterministic: False
  enabled: True

dataloader:
  batch_size: 80
  pin_memory: true
  num_workers: 4
  train_ds:
    root: data/ImageNet
    split: train
  val_ds:
    root: data/ImageNet
    split: val

transform:
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  out_size: [224, 224]

module:
  optimizers:
    optim:
      name: SGD
      params:
        lr: 0.1 # 0.133? 0.1 * ((2*96)/(4*36)) scale LR from paper by my batch_size (96) and GPU (2)
        momentum: 0.9
        weight_decay: 0.0001
        nesterov: True
  lr_schedulers:
    optim:
      name: MultiStepLR
      interval: epoch
      params:
        milestones: [30, 60, 90]
        gamma: 0.1

net:
  params:
    C: 32
    num_classes: 1000

inference:
  input_size: 256
  ckpt_path: pretrained/hrnet_32.pt
